{"pred": " The article does not mention which Facebook pages they looked at.", "answers": ["FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney", "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."], "all_classes": null, "length": 3411}
{"pred": " The latent context used to predict instructor intervention is the reply structure in discussion forums.", "answers": ["the series of posts that trigger an intervention"], "all_classes": null, "length": 3732}
{"pred": " The article does not mention any other evaluation metrics.", "answers": ["F-score, Kappa", "Unanswerable"], "all_classes": null, "length": 3544}
{"pred": " The baselines used in the experiments are stacked LSTMs.", "answers": ["(i) models that use plain stacked LSTMs, (ii) models with different INLINEFORM0, (iii) models without INLINEFORM1, (iv) models that integrate lower contexts via peephole connections"], "all_classes": null, "length": 3224}
{"pred": " jiant is compatible with models in Python.", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 2284}
{"pred": " The experts are not comparable to real-world users.", "answers": ["No"], "all_classes": null, "length": 3843}
{"pred": " Yes, the method of using shallow syntax features can help in sentiment classification task improvement.", "answers": ["Yes", "No"], "all_classes": null, "length": 2317}
{"pred": " The evaluation datasets used in the experiments are not mentioned in the article.", "answers": ["SemEval-2016 Challenge Task 5 BIBREF27 , BIBREF28", " English reviews ,  restaurant reviews from four different languages (Spanish, Turkish, Dutch, Russian)"], "all_classes": null, "length": 2720}
{"pred": " The article discusses a medical abbreviation disambiguation task on MIMIC-III notes and Case Reports articles. The authors propose a neural topic-attention model with contextualized word embeddings and topic information to solve the abbreviation disambiguation task. They also evaluate the performance of their model on a balanced testing dataset and show improvements in accuracy and F1 score for rare senses. The article also discusses the limitations of the dataset and the difficulty in obtaining training samples for rare abbreviation terms.", "answers": ["7.36% on accuracy and 9.69% on F1 score", "it has 0.024 improvement in accuracy comparing to ELMO Only and  0.006 improvement in F1 score  comparing to ELMO Only too"], "all_classes": null, "length": 2890}
{"pred": " The article does not mention whether the datasets use transcribed text or determine text from the audio.", "answers": ["They use text transcription.", "both"], "all_classes": null, "length": 3198}
{"pred": " The clustering algorithms used are not mentioned in the article.", "answers": ["CLUTO, Carrot2 Lingo", "simple clustering algorithm which uses the cosine similarity between word embeddings"], "all_classes": null, "length": 3039}
{"pred": " The article does not provide information on the type of neural model used.", "answers": ["Bert + Unanswerable", "CNN, BERT"], "all_classes": null, "length": 3845}
{"pred": " The pivot-based baselines are not mentioned in the article.", "answers": ["pivoting, pivoting$_{\\rm m}$", "firstly translates a source language into the pivot language which is later translated to the target language"], "all_classes": null, "length": 3815}
{"pred": " The article does not mention any datasets used.", "answers": ["Friends, EmotionPush", "EmotionLines BIBREF6"], "all_classes": null, "length": 3178}
{"pred": " The evaluation protocols provided are:\n\n1. Text-dependent speaker verification:\n- Target-Correct: same device\n- Target-Wrong: different device\n- Imposter-Correct: same device\n- Imposter-Wrong: different device\n- Random: different device\n- All: all devices\n\n2. Text-dependent speaker verification with phone-level transcription:\n- Target-Correct: same device\n- Target-Wrong: different device\n- Imposter-Correct: same device\n- Imposter-Wrong: different device\n- Random: different device\n- All: all devices\n\n3.", "answers": ["three experimental setups with different numbers of speakers in the evaluation set, three experimental setups with different number of speaker in the evaluation set are defined,  first one, respondents with at least 17 recording sessions are included to the evaluation set, respondents with 16 sessions to the development and the rest of respondents to the background set, second setup, respondents with at least 8 sessions are included to the evaluation set, respondents with 6 or 7 sessions to the development and the rest of respondents to the background set"], "all_classes": null, "length": 3880}
{"pred": " The question is asking about the Gaussian-masked directional multi-head attention mechanism used in the Chinese word segmentation model. The mechanism is described as a variant of standard self-attention that uses directional information to capture the localness and directional information of sentences. The mechanism is used to generate the representation of sentences at once and contain the information of the sentence which is different from RNN that process characters of sentences one by one. The mechanism is also used to capture the features of gaps and generate the representation of sentences at once.", "answers": ["pays attentions to adjacent characters and casts a localness relationship between the characters as a fixed Gaussian weight assuming the weight relies on the distance between characters", "Gaussian-masked directional attention can be described as a function to map queries and key-value pairs to the representation of input, Gaussian-masked directional attention expects to pay attention to the adjacent characters of each positions and cast the localness relationship between characters as a fix Gaussian weight for attention, Gaussian weight only relys on the distance between characters"], "all_classes": null, "length": 3612}
{"pred": " The article does not provide information on how much training data from the non-English language is used by the system.", "answers": ["No data. Pretrained model is used."], "all_classes": null, "length": 3409}
{"pred": " The article discusses the differences between attention and word alignment in neural machine translation. The authors investigate whether attention is always better than word alignment and whether attention is equivalent to traditional alignment. They also examine the relationship between attention and word alignment and the impact of attention on translation quality. The article concludes that attention is not always better than word alignment and that attention can be different from alignment in some cases.", "answers": ["For certain POS tags, e.g. VERB, PRON.", "most word alignments only involve one or a few words, attention can be distributed more freely"], "all_classes": null, "length": 3366}
{"pred": " The article does not mention which model they use for end-to-end speech recognition.", "answers": ["RNN", " Recurrent Neural Network (RNN)"], "all_classes": null, "length": 1644}
{"pred": " The baseline is not mentioned in the given text.", "answers": ["CNN modelBIBREF0, Stanford CRF modelBIBREF21", "Bam et al. SVM, Ma and Hovy w/glove, Lample et al. w/fastText, Lample et al. w/word2vec"], "all_classes": null, "length": 2836}
{"pred": " The paper was published in 2018.", "answers": ["Unanswerable"], "all_classes": null, "length": 3885}
{"pred": " The article does not provide information on how many people participated in their evaluation study of table-to-text models.", "answers": ["about 500", "Unanswerable"], "all_classes": null, "length": 3831}
{"pred": " The question is \"What models are used in the experiment?\" and the answer is \"The models used in the experiment are a linear SVM, a bidirectional Long Short-Term Memory (BiLSTM) model, and a CNN model.\"", "answers": ["linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM), Convolutional Neural Network (CNN)", "linear SVM trained on word unigrams,  bidirectional Long Short-Term-Memory (BiLSTM),  Convolutional Neural Network (CNN) "], "all_classes": null, "length": 2250}
{"pred": " The article explores the use of neural networks for named entity recognition (NER) in Nepali language. The authors experiment with various neural network architectures, including BiLSTM, BiLSTM+CNN, BiLSTM+CRF, and BiLSTM+CNN+CRF, and compare their performance with a baseline model. They also experiment with different word embeddings, including pre-trained embeddings and randomly initialized embeddings. The article concludes that the BiLSTM+CNN+CRF model with pre-trained embeddings performs the best. The article also presents a novel NER dataset for Nepali language and discusses the importance of data augmentation and cross-lingual learning", "answers": ["BiLSTM, BiLSTM-CNN, BiLSTM-CRF, BiLSTM-CNN-CRF", "BiLSTMBIBREF14, BiLSTM+CNNBIBREF20, BiLSTM+CRFBIBREF1, BiLSTM+CNN+CRFBIBREF2, CNN modelBIBREF0 and Stanford CRF modelBIBREF21"], "all_classes": null, "length": 2838}
{"pred": " The vocabulary of word-like or phoneme-like units is automatically discovered using unsupervised acoustic unit discovery (AUD) or unsupervised term discovery (UTD).", "answers": ["Zero Resource Toolkit (ZRTools) BIBREF7"], "all_classes": null, "length": 3381}
{"pred": " The article tests the BERT model.", "answers": ["BERTbase", "BERTbase"], "all_classes": null, "length": 3852}
{"pred": " The article discusses the impact of preprocessing on keyphrase extraction performance. The authors experimented with four different keyphrase extraction models and found that the performance of the models varied significantly depending on the preprocessing stage. The models were re-assessed at three increasingly sophisticated levels of preprocessing, and the results showed that the performance of the models varied significantly depending on the preprocessing stage. The authors also found that the performance of the models was affected by the presence of noisy text in the documents. The article concludes that the performance of keyphrase extraction models is affected by the preprocessing stage and that the performance of the models varies significantly depending on the preprocessing stage.", "answers": ["Answer with content missing: (LVL1, LVL2, LVL3) \n- Stanford CoreNLP\n- Optical Character Recognition (OCR) system, ParsCIT \n- further abridge the input text from level 2 preprocessed documents to the following: title, headers, abstract, introduction, related work, background and conclusion."], "all_classes": null, "length": 1822}
{"pred": " The article does not provide information on whether pre-training is effective in their evaluation.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 2077}
{"pred": " The article does not mention any datasets used.", "answers": ["MIMIC-III", "MIMIC-III"], "all_classes": null, "length": 2992}
{"pred": " The dataset for each step of hierarchy is not mentioned in the article.", "answers": ["Level A: 14100 Tweets\nLevel B: 4640 Tweets\nLevel C: 4089 Tweets"], "all_classes": null, "length": 2255}
{"pred": " The article discusses the differences between attention and word alignment in neural machine translation. The authors investigate whether attention is equivalent to word alignment and whether attention is capable of modeling alignment quality. They also examine the relationship between attention and word prediction and analyze the attention distribution. The article concludes that attention is not always helpful for translating words and that attention can be used to capture other relevant information in addition to the aligned words.", "answers": ["it captures other information rather than only the translational equivalent in the case of verbs", "Alignment points of the POS tags."], "all_classes": null, "length": 3372}
{"pred": " The baselines mentioned in the article are:\n\n1. BOW: Bag-of-words model\n2. TFIDF: Term frequency-inverse document frequency model\n3. Neural-based word embedding: GloVe word embedding\n4. TextCNN: TextCNN model with three pre-training tasks\n5. Logistic Regression: Logistic Regression model\n6. Random Forest: Random Forest model\n7. TextCNN: TextCNN model with three pre-training tasks\n8. BERT: Bidirectional Encoder Representations from Transformers\n9. FriendsBERT: FriendsBERT model\n10. ChatBERT:", "answers": ["BOW-LR, BOW-RF. TFIDF-RF, TextCNN, C-TextCNN", "bag-of-words (BOW), term frequency–inverse document frequency (TFIDF), neural-based word embedding, Logistic Regression (LR), Random Forest (RF), TextCNN BIBREF10 with initial word embedding as GloVe"], "all_classes": null, "length": 3181}
{"pred": " The article does not provide information on how many tags they look at.", "answers": ["Unanswerable", "48,705"], "all_classes": null, "length": 3307}
{"pred": " The article does not provide information on the architecture of their model.", "answers": ["follow the architecture in berard2018end, but have 3 decoder layers like that in pino2019harnessing"], "all_classes": null, "length": 2424}
{"pred": " The article does not provide any information about the data used.", "answers": [" Penn Treebank, WikiText2", "Penn Treebank (PTB) , WikiText2 (WT-2)"], "all_classes": null, "length": 3302}
{"pred": " The article does not mention whether graphical models are used.", "answers": ["No", "No"], "all_classes": null, "length": 3158}
{"pred": " The question is unanswerable based on the information in the article.", "answers": ["While there has been existing work on reducing NLP model vocabulary sizes BIBREF15, distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes.", "distillation techniques cannot utilize these, since they require the student and teacher models to share the same vocabulary and output space. This profoundly limits their potential to further reduce model sizes."], "all_classes": null, "length": 3570}
{"pred": " The baseline method used is the corpus-based approach.", "answers": ["using word2vec to create features that are used as input to the SVM", "use the word2vec algorithm, create several unsupervised hand-crafted features, generate document vectors and feed them as input into the support vector machines (SVM) approach"], "all_classes": null, "length": 3820}
{"pred": " The ancient Chinese dataset is created by the authors of the paper.", "answers": ["ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era", "Ancient Chinese history records in several dynasties and articles written by celebrities during 1000BC-200BC collected from the internet "], "all_classes": null, "length": 3722}
{"pred": " The answer is \"unanswerable\".", "answers": ["No"], "all_classes": null, "length": 1561}
{"pred": " The paper suggests that the use of a recurrent neural model in a sequential manner, along with a set of features including emotion, morality, and other text-based features, is the most predictive set of features to detect fake news.", "answers": ["words embeddings, style, and morality features", "words embeddings, style, and morality features"], "all_classes": null, "length": 2091}
{"pred": " The question is unanswerable as the article does not provide information on the datasets used for evaluation.", "answers": ["United Nations Parallel Corpus, IIT Bombay corpus, OpenSubtitles 2018"], "all_classes": null, "length": 3405}
{"pred": " The article discusses the incorporation of subword information into word embeddings using the Skip-gram model. The authors compare their approach to the popular fastText model and the LexVec model, which uses word-level representations. They evaluate the impact of subword information on word similarity and word analogy tasks, as well as on downstream tasks. The results show that subword information improves rare word representation and that it is more robust to OOV words. The authors also investigate the question of whether subword information can be used to build word embeddings for different languages.", "answers": ["Unanswerable", "English"], "all_classes": null, "length": 2009}
{"pred": " The dataset is not balanced between speakers of different L1s.", "answers": ["No", "No"], "all_classes": null, "length": 1899}
{"pred": " The collection of COVID-19 literature is over 45,000 scholarly articles.", "answers": ["45,000 scholarly articles, including over 33,000 with full text"], "all_classes": null, "length": 2150}
{"pred": " The question does not provide any information about what baseline models are compared to the proposed model.", "answers": ["support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self", "support vector machine classifier (SVM), logistic regression classifier (LR), Naive Bayes classifier (NB), random forest (RF), CNN, LSTM , LSTM-soft, LSTM-self"], "all_classes": null, "length": 2895}
{"pred": " The article does not provide information on the number of electrodes used on the subject in EEG sessions.", "answers": ["1913 signals", "Unanswerable"], "all_classes": null, "length": 2361}
{"pred": " The different modules in Macaw are:\n\n1. File IO\n2. Question Answering\n3. Recommendation\n4. Natural Language Interface\n5. CLA\n6. Contributor License Agreement (CLA)\n7. Open Source Code of Conduct\n8. Microsoft Open Source Code of Conduct\n9. Macaw\n10. Macaw's architecture\n11. Macaw's modular design\n12. Macaw's support for multi-turn, multi-modal, and mixed-initiative interactions\n13. Macaw's support for conversational search, question answering, recommendation, and natural language interface\n14. Mac", "answers": ["Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation", "Co-Reference Resolution, Query Generation, Retrieval Model, Result Generation"], "all_classes": null, "length": 1701}
{"pred": " Yes, their indexing-based method can be applied to create other QA datasets in other domains, and not just Wikipedia.", "answers": ["Unanswerable"], "all_classes": null, "length": 1913}
{"pred": " The article does not mention any accents present in the corpus.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 3794}
{"pred": " The experiments are performed on the SQuAD dataset.", "answers": ["SQuAD", "SQuAD"], "all_classes": null, "length": 3757}
{"pred": " The article does not mention which dataset the models are trained on.", "answers": ["relation classification dataset of the SemEval 2010 task 8", "SemEval 2010 task 8 BIBREF8"], "all_classes": null, "length": 2393}
{"pred": " The article does not provide information on the size of the corpora used to train ELMo.", "answers": ["2174000000, 989000000", "2174 million tokens for English and 989 million tokens for Russian"], "all_classes": null, "length": 2958}
{"pred": " The qualitative experiments performed on benchmark datasets include word similarity and entailment datasets such as Text8, SCWS, SCWS-R, SCWS-S, RG, YP, MTurk-287, MTurk-771, and RW. The proposed approach, GM$\\_$KL, outperforms other approaches on these datasets.", "answers": ["Spearman correlation values of GM_KL model evaluated on the benchmark word similarity datasets.\nEvaluation results of GM_KL model on the entailment datasets such as entailment pairs dataset created from WordNet, crowdsourced dataset of 79 semantic relations labelled as entailed or not and annotated distributionally similar nouns dataset.", "Given a query word and component id, the set of nearest neighbours along with their respective component ids are listed"], "all_classes": null, "length": 2220}
{"pred": " The article discusses the problem of data imbalance in NLP tasks and proposes a method to address it using a dice loss. The dice loss is a hard version of F1 score that performs as a soft version of precision and recall. The article also explores the effect of hyperparameters in the dice loss and shows that it can help narrow the gap between training objectives and evaluation metrics. The article concludes by stating that the proposed method improves F1 for paraphrase identification.", "answers": ["Using DSC loss improves the F1 score by +0.58 for MRPC and +0.73 for QQP", "+0.58"], "all_classes": null, "length": 3566}
{"pred": " The article does not provide information on how they calculate variance from the model outputs.", "answers": ["reducing the variance of an estimator,  EGL method in BIBREF3 is almost the same as Eq. ( EQREF8 ), except the gradient's norm is not squared in BIBREF3", " Fisher Information Ratio"], "all_classes": null, "length": 1671}
{"pred": " The encoder has an LSTM decoder.", "answers": ["LSTM", "LSTM"], "all_classes": null, "length": 2289}
{"pred": " The questions in the dataset are natural language questions that require reasoning skills to answer.", "answers": ["These 8 tasks require different competencies and a different level of understanding of the document to be well answered"], "all_classes": null, "length": 3817}
{"pred": " The article does not mention whether other baselines were tested to compare with the neural baseline.", "answers": ["SVM, No-Answer Baseline (NA) , Word Count Baseline, Human Performance", "No-Answer Baseline (NA), Word Count Baseline, Human Performance"], "all_classes": null, "length": 3855}
{"pred": " The article does not provide information on the number of documents in the new corpus.", "answers": ["53 documents", "53 documents"], "all_classes": null, "length": 2667}
{"pred": " The article does not mention where the recipes are obtained from.", "answers": ["from Food.com"], "all_classes": null, "length": 2649}
{"pred": " The article does not provide information on how the resulting word embeddings are evaluated.", "answers": ["We also evaluate all five models on downstream tasks from the VecEval suite BIBREF13 , using only the tasks for which training and evaluation data is freely available: chunking, sentiment and question classification, and natural language identification (NLI). The default settings from the suite are used, but we run only the fixed settings, where the embeddings themselves are not tunable parameters of the models, forcing the system to use only the information already in the embeddings."], "all_classes": null, "length": 2083}
{"pred": " The 10 other phenotypes that are annotated are:\n- Chronic Obstructive Pulmonary Disease (COPD)\n- Chronic Kidney Disease (CKD)\n- Diabetes Mellitus\n- Heart Failure\n- Hypertension\n- Liver Disease\n- Obesity\n- Sleep Apnea\n- Stroke\n- Urinary Tract Infection (UTI)", "answers": ["Adv. Heart Disease, Adv. Lung Disease, Alcohol Abuse, Chronic Neurologic Dystrophies, Dementia, Depression, Developmental Delay, Obesity, Psychiatric disorders and Substance Abuse"], "all_classes": null, "length": 1651}
{"pred": " The average length of the essays is around 200 words.", "answers": ["204 tokens", "Most texts, however, range roughly from 150 to 250 tokens."], "all_classes": null, "length": 1898}
{"pred": " The question does not provide any textual patterns that are extracted.", "answers": ["(VVD shop_VV0 II, VVD shopping_VVG II)", "patterns for generating all types of errors"], "all_classes": null, "length": 2133}
{"pred": " Yes, they study numerical properties of their obtained vectors.", "answers": ["No", "No"], "all_classes": null, "length": 3974}
{"pred": " The Random Kitchen Sink approach is a method used in machine learning to improve the evaluation scores of a classification task. It involves explicitly mapping the data to a higher dimension where the data becomes linearly separable. The method is used to improve the evaluation scores of the proposed RKS approach for the Offensive Language Identification task in SemEval 2019.", "answers": ["Random Kitchen Sink method uses a kernel function to map data vectors to a space where linear separation is possible.", "explicitly maps data vectors to a space where linear separation is possible, RKS method provides an approximate kernel function via explicit mapping"], "all_classes": null, "length": 2361}
{"pred": " The article compares the performance of various strategies to add pre-trained language model representations to sequence to sequence models for neural machine translation and abstractive summarization. The strategies include inputting ELMo-style representations to the encoder, fine-tuning the language model, and adding representations to the decoder. The article also presents results on various simulated labeled data scenarios and experiments on the WMT'18 English-Turkish and English-German tasks. The article concludes that pre-trained representations are most effective in low-resource settings but gains are still possible when more labeled data is available.", "answers": ["BIBREF11 , BIBREF26 "], "all_classes": null, "length": 1912}
{"pred": " The article discusses the use of artificial data for error detection, specifically for the FCE and CoNLL 2014 datasets. The authors propose two methods for generating artificial data: a machine translation system and a pattern-based method. The machine translation system uses a phrase-based SMT system to translate from correct to incorrect sentences, while the pattern-based method uses a statistical language model to generate errors. The authors also investigate combining the two methods and show that the combination outperforms the machine translation system alone. The article concludes that the use of artificial data can significantly improve error detection performance.", "answers": ["Combining  pattern based and Machine translation approaches gave the best overall F0.5 scores. It was 49.11 for FCE dataset  , 21.87 for the first annotation of  CoNLL-14, and 30.13 for the second annotation of CoNLL-14. "], "all_classes": null, "length": 2164}
{"pred": " The article discusses a method for encoding social media posts as character vectors, which can be used for tasks such as hashtag prediction. The method is compared to a word-based approach and is shown to be more robust to rare words and perform comparably to the word-based approach for in-vocabulary tokens. The method is also shown to be able to predict hashtags for a held-out test set. The article also mentions some other tasks that the method can be used for, such as hashtag prediction.", "answers": ["None"], "all_classes": null, "length": 2473}
{"pred": " The experts used for annotation were not mentioned in the article.", "answers": ["Individuals with legal training", "Yes"], "all_classes": null, "length": 3846}
{"pred": " The article provides a review of word segmentation approaches and systems for Vietnamese, including morphological, lexical, and machine learning-based methods. The article also discusses the evaluation and segmentation of Vietnamese word segmentation toolkits, such as vnTokenizer and JVnSegmenter, using the EVBNews corpus. The article concludes by mentioning the challenges and future directions for Vietnamese word segmentation.", "answers": ["Maximum Entropy, Weighted Finite State Transducer (WFST),  support vector machines (SVM), conditional random fields (CRF)", "Maximum matching, Hidden Markov model , Maximum Entropy, Conditional Random Fields , Support Vector Machines"], "all_classes": null, "length": 3471}
{"pred": " The question is unanswerable as the article does not provide any information on the specific NER models that were evaluated.", "answers": ["Stanford NER, spaCy 2.0 , recurrent model with a CRF top layer", "Stanford NER, spaCy 2.0, recurrent model with a CRF top layer"], "all_classes": null, "length": 2759}
{"pred": " The paper uses the WN18 and FB15K datasets for evaluation.", "answers": ["WordNet BIBREF0, Freebase BIBREF1, WN18 (a subset of WordNet) BIBREF24 , FB15K (a subset of Freebase) BIBREF2"], "all_classes": null, "length": 3367}
{"pred": " The baseline model used is the LastStateRNN model.", "answers": [" LastStateRNN, AvgRNN, AttentionRNN", "LastStateRNN, AvgRNN, AttentionRNN "], "all_classes": null, "length": 2823}
{"pred": " The article does not provide information on what cyberbullying topics were addressed.", "answers": ["personal attack, racism, and sexism", "racism, sexism, personal attack, not specifically about any single topic"], "all_classes": null, "length": 3244}
{"pred": " Yes, the article reports results only on English data.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 3634}
{"pred": " The dataset used for this study is the Twitter dataset.", "answers": ["BIBREF12 , BIBREF13", "an existing, annotated Twitter dataset that was constructed based on a hierarchical model of depression-related symptoms BIBREF12 , BIBREF13"], "all_classes": null, "length": 1939}
{"pred": " The article discusses the problem of identifying the language of short pieces of text in South Africa, which is a multilingual country with 11 official languages. The article proposes a hierarchical naive Bayesian classifier with character (2, 4, and 6)-grams, word unigrams and bigrams, and a lexicon based classifier for LID. The article also compares the proposed algorithm to other LID algorithms and evaluates its performance against existing datasets and shared tasks. The article concludes that the proposed algorithm performs well compared to other LID algorithms and that further research is needed to improve the accuracy of LID.", "answers": ["Nguni languages (zul, xho, nbl, ssw), Sotho languages (nso, sot, tsn)", "The Nguni languages are similar to each other, The same is true of the Sotho languages"], "all_classes": null, "length": 1877}
{"pred": " The sentiment analysis dataset used is the IMDb dataset of movie reviews by BIBREF0.", "answers": ["IMDb dataset of movie reviews", "IMDb"], "all_classes": null, "length": 2327}
{"pred": " The system's performance was not mentioned in the article.", "answers": ["accuracy and F1-score of 89.6% and 89.2%, respectively", "accuracy and F1-score of 89.6% and 89.2%, respectively"], "all_classes": null, "length": 3313}
{"pred": " The approach outperforms K-means, LEM, and DPEMM.", "answers": ["K-means, LEM BIBREF13, DPEMM BIBREF14", "K-means, LEM, DPEMM"], "all_classes": null, "length": 3841}
{"pred": " The PolyResponse engine is used for restaurant search and booking system in 8 languages: English (Edinburgh), German (Berlin), Spanish (Madrid), Mandarin (Taipei), Polish (Warsaw), Russian (Moscow), Korean (Seoul), and Serbian (Belgrade).", "answers": ["English, German, Spanish, Mandarin, Polish, Russian, Korean and Serbian", "English (Edinburgh), German (Berlin), Spanish (Madrid), Mandarin (Taipei), Polish (Warsaw), Russian (Moscow), Korean (Seoul), and Serbian (Belgrade)"], "all_classes": null, "length": 2754}
{"pred": " The sources of the datasets are not explicitly mentioned in the article.", "answers": ["rupnik2016news", "rupnik2016news, Deutsche Welle's news website"], "all_classes": null, "length": 3160}
{"pred": " The lexicon is the same for all languages.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 1868}
{"pred": " The article does not mention any other sentence embeddings methods being evaluated.", "answers": ["GloVe, BERT, Universal Sentence Encoder, TF-IDF, InferSent", "Avg. GloVe embeddings, Avg. fast-text embeddings, Avg. BERT embeddings, BERT CLS-vector, InferSent - GloVe and Universal Sentence Encoder."], "all_classes": null, "length": 3862}
{"pred": " The article discusses the development of a sentence embedding method called Sentence-BERT (SBERT) that can be used for various sentence-pair regression tasks. SBERT is based on the BERT network and can be fine-tuned to yield sentence embeddings that are suitable for various tasks such as clustering, triplet loss, and semantic search. SBERT is evaluated on various sentence embedding tasks and achieves state-of-the-art performance on seven Semantic Textual Similarity (STS) benchmark tasks. SBERT is also shown to be faster than average GloVe embeddings and InferSent.", "answers": ["MR, CR, SUBJ, MPQA, SST, TREC, MRPC", "MR: Sentiment prediction for movie reviews snippets on a five start scale BIBREF25.\n\nCR: Sentiment prediction of customer product reviews BIBREF26.\n\nSUBJ: Subjectivity prediction of sentences from movie reviews and plot summaries BIBREF27.\n\nMPQA: Phrase level opinion polarity classification from newswire BIBREF28.\n\nSST: Stanford Sentiment Treebank with binary labels BIBREF29.\n\nTREC: Fine grained question-type classification from TREC BIBREF30.\n\nMRPC: Microsoft Research Paraphrase Corpus from parallel news sources BIBREF31.", "Semantic Textual Similarity, sentiment prediction, subjectivity prediction, phrase level opinion polarity classification, Stanford Sentiment Treebank, fine grained question-type classification."], "all_classes": null, "length": 3861}
{"pred": " The vocabulary of users (e.g., INLINEFORM0 when searching for books on Amazon) is, however, a very low vocabulary.", "answers": ["33,663", "33,663 distinct review keywords "], "all_classes": null, "length": 3305}
{"pred": " The article does not mention any additional features or context proposed.", "answers": ["using tweets that one has replied or quoted to as contextual information", "text sequences of context tweets"], "all_classes": null, "length": 2060}
{"pred": " Yes, they evaluate their learned representations on downstream tasks.", "answers": ["No", "No"], "all_classes": null, "length": 1906}
{"pred": " The article does not mention if the model is built to automatically detect demographic, linguistic, or psychological dimensions of people.", "answers": ["No", "No"], "all_classes": null, "length": 1443}
{"pred": " The best performing model among the author's submissions is the ensemble of the three classifiers (CNN, BERT, and LSTM-CRF) with BERTSentEmb, which has a F1 score of 0.673 on the development set of the SLC task.", "answers": ["For SLC task, the \"ltuorp\" team  has the best performing  model (0.6323/0.6028/0.6649 for F1/P/R  respectively) and for FLC task the \"newspeak\" team  has the best performing  model (0.2488/0.2863/0.2201 for F1/P/R respectively)."], "all_classes": null, "length": 1541}
{"pred": " The corpus used for the task is the Diachronic Usage Relatedness (DURel) gold standard data set.", "answers": ["DTA18, DTA19", "Diachronic Usage Relatedness (DURel) gold standard data set"], "all_classes": null, "length": 1908}
{"pred": " The dataset is too large to provide a concise answer.", "answers": ["13,757", "10,898 articles, 17,794 tweets, and 13,757 crowdsourced question-answer pairs"], "all_classes": null, "length": 3704}
{"pred": " The classifiers that have been trained are KNN, RF, SVM, and MLP.", "answers": ["KNN\nRF\nSVM\nMLP", " K Nearest Neighbors (KNN), Random Forest (RF), Support Vector Machine (SVM), Multi-layer Perceptron (MLP)"], "all_classes": null, "length": 1639}
{"pred": " The new context representation is obtained by splitting the context into two parts: a left context, a left entity and a middle context, and a right entity. The middle context is split into two parts: a left entity and a right entity. The left context and the right context are used to predict the relation between the left entity and the middle context, and the middle context and the right entity, respectively. The middle context is split into two parts because the left context and the right context may contain different information about the relation between the left entity and the middle context.", "answers": ["They use two independent convolutional and max-pooling layers on (1) a combination of the left context, the left entity and the middle context; and (2) a combination of the middle context, the right entity and the right context. They concatenated the two results after pooling to get the new context representation."], "all_classes": null, "length": 2435}
{"pred": " The question is unanswerable as it is not clear what is meant by \"multi-granularity\" and \"multi-tasking\" in the context of the article.", "answers": ["An output layer for each task", "Multi-tasking is addressed by neural sequence tagger based on LSTM-CRF and linguistic features, while multi-granularity is addressed by ensemble of LSTM-CRF and BERT."], "all_classes": null, "length": 1514}
{"pred": " CORD-19 is an open-access online database of scholarly articles, including coronavirus-related articles, published after November 2019.", "answers": ["which contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses", "contains over 45,000 scholarly articles, including over 33,000 with full text, about COVID-19, SARS-CoV-2, and related coronaviruses"], "all_classes": null, "length": 2156}
{"pred": " The article does not provide information on the size of the real-life dataset.", "answers": ["26972", "26972 sentences"], "all_classes": null, "length": 3040}
{"pred": " The article discusses the use of neural networks for grammar induction, specifically focusing on the compound PCFG. The authors propose a novel approach to grammar induction that utilizes a continuous latent vector to obtain a distribution over trees. They also explore the use of a neural PCFG as a generative model for grammar induction. The article also explores the use of RNNGs for grammar induction and the use of a RNNG for supervised grammar induction. The article concludes with a discussion of the limitations of the current approach and potential future directions.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 2533}
{"pred": " The backoff strategies are used to handle the case where the ScRNN model fails to predict the correct word. They involve using a neutral word as a fallback option when the model is unable to predict the correct word. The neutral word is chosen based on the output of the ScRNN model, and it is used as the input to the downstream classifier. The backoff strategies are effective in mitigating the impact of adversarial attacks on the downstream classifier.", "answers": ["In pass-through, the recognizer passes on the possibly misspelled word, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Pass-through passes the possibly misspelled word as is, backoff to neutral word backs off to a word with similar distribution across classes and backoff to background model backs off to a more generic word recognition model trained with larger and less specialized corpus.", "Backoff to \"a\" when an UNK-predicted word is encountered, backoff to a more generic word recognition model when the model predicts UNK"], "all_classes": null, "length": 4210}
{"pred": " The dialogues used to train the policy of a dialogue manager (DM) are from a corpus of restaurant reservation dialogues.", "answers": ["DSTC2", "The manual transcriptions of the DSTC2 training set "], "all_classes": null, "length": 4820}
{"pred": " The article does not provide information on the metrics used for evaluation.", "answers": ["BLEU-4, NIST-4, ROUGE-4", "BLEU-4, NIST-4, ROUGE-4"], "all_classes": null, "length": 4460}
{"pred": " The article does not mention any state-of-the-art models.", "answers": ["SVM , CNN , GRU , CNN/GRU+law, r-net , AoA ", "SVM with lexical features in accordance with previous works BIBREF16 , BIBREF17 , BIBREF1 , BIBREF15 , BIBREF4, attention-based method BIBREF3 and other methods we deem important, some off-the-shelf RC models, including r-net BIBREF5 and AoA BIBREF6 , which are the leading models on SQuAD leaderboard"], "all_classes": null, "length": 4106}
{"pred": " The article discusses the use of deep learning techniques for Arabic diacritization, specifically for Modern Standard Arabic (MSA) and Classical Arabic (CA). The article presents a novel approach for MSA diacritization that uses a character-level bidirectional long short-term memory (biLSTM) based recurrent neural network (RNN) model with rich features. The model achieves a word error rate (WER) of 2.5% for MSA and a case ending error rate (CEER) of 3.7% for MSA. The article also presents a feature-rich RNN-based model for MSA and CA that achieves", "answers": ["POS, gender/number and stem POS"], "all_classes": null, "length": 4719}
{"pred": " The question is unanswerable based on the information in the article.", "answers": ["dimension corresponding to the concept that the particular word belongs to"], "all_classes": null, "length": 6182}
{"pred": " The data is in English.", "answers": ["English , German, French"], "all_classes": null, "length": 4173}
{"pred": " The article does not mention whether the framework automatically optimizes for hyperparameters.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 4465}
{"pred": " The question is unanswerable as it is not specified which two news domains are country-independent.", "answers": ["mainstream news and disinformation", "mainstream and disinformation news"], "all_classes": null, "length": 4856}
{"pred": " The experiments are performed on the CoinCollector, CookingWorld, and the 4,440 games of \"First TextWorld Problems\" BIBREF8.", "answers": ["CoinCollector , CookingWorld ", "CoinCollector, CookingWorld"], "all_classes": null, "length": 4924}
{"pred": " The two metrics proposed are F1 score for the set generation task and R@10/50 for the absent keyphrase generation task.", "answers": ["average unique predictions, randomly sample 2000 decoder hidden states at INLINEFORM4 steps following a delimiter ( INLINEFORM5 ) and apply an unsupervised clustering method (t-SNE BIBREF35 )"], "all_classes": null, "length": 4581}
{"pred": " The article does not mention any biases that their model captures.", "answers": ["Data annotation biases where tweet containing disrespectful words are annotated as hate or offensive without any presumption about the social context of tweeters"], "all_classes": null, "length": 4111}
{"pred": " The article discusses a hierarchical encoder for structured data, specifically for data-to-text generation. The encoder is designed to capture the structure of the data, and the decoder is designed to generate fluent and domain-specific expressions. The article also compares the proposed model to baselines and shows that it outperforms them in terms of BLEU score and is generally better on qualitative metrics. The article concludes by noting that future possible improvements are listed.", "answers": ["rther constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions", "to further constrain the model on the data structure in order to prevent inaccurate of even contradictory descriptions"], "all_classes": null, "length": 4704}
{"pred": " The additive modification to the objective function is to modify the objective function of the GloVe algorithm by adding a cost term that favors an increase in the interpretability of word embeddings. This is achieved by modifying the objective function to include a cost term that is proportional to the cosine similarity between the input word and a concept word-group. The proposed method is based on the idea that the cost term should be modified to favor an increase in interpretability without sacrificing the semantic structure of the original word embedding. The proposed method is compared to three other word embedding algorithms in terms of interpretability and performance, and is shown to significantly improve interpretability", "answers": ["The cost function for any one of the words of concept word-groups is modified by the introduction of an additive term to the cost function. . Each embedding vector dimension is first associated with a concept. For a word belonging to any one of the word-groups representing these concepts, the modified cost term favors an increase for the value of this word's embedding vector dimension corresponding to the concept that the particular word belongs to,", "An additive term added to the cost function for any one of the words of concept word-groups"], "all_classes": null, "length": 6244}
{"pred": " The article does not report results only on English data.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 7837}
{"pred": " The document-level encoder is novel in that it is trained on the entire document, rather than just the first sentence or paragraph.", "answers": ["Bert model have a maximum length of 512; we overcome this limitation by adding more position embeddings, we insert external [cls] tokens at the start of each sentence, and each [cls] symbol collects features for the sentence preceding it, document representations are learned hierarchically"], "all_classes": null, "length": 4404}
{"pred": " The article discusses the use of sparse attention mechanisms in Transformers, which can yield improved interpretability compared to softmax transformers. The sparse attention mechanism used in the model is adaptively sparse, allowing for different sparse patterns for different attention heads. The model is capable of attending to different parts of a sequence, and the sparse attention mechanism allows for the selection of relevant context words. The model is also capable of learning different sparsity patterns for different attention heads, allowing for more flexible behavior.", "answers": ["the attention heads in the proposed adaptively sparse Transformer can specialize more and with higher confidence", "We introduce sparse attention into the Transformer architecture"], "all_classes": null, "length": 4902}
{"pred": " The article discusses the use of neural machine translation models for morphologically rich languages like Tamil. The article describes the use of a neural translation model for English-Tamil machine translation, which uses a combination of parallel and monolingual corpora to train the model. The model uses a bidirectional encoder-decoder architecture with a context vector and a weighted sum of the hidden states of the encoder. The article also discusses the use of a morphological segmentation tool to improve the performance of the translation. The article concludes by stating that the use of morphological segmentation can improve the efficacy of the attention mechanism.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 5331}
{"pred": " The article does not provide information on how many users they look at.", "answers": ["22,880 users", "20,000"], "all_classes": null, "length": 4160}
{"pred": " unanswerable", "answers": ["sentence"], "all_classes": null, "length": 4369}
{"pred": " The article does not provide information on the labels available for antisocial events in datasets.", "answers": ["The Conversations Gone Awry dataset is labelled as either containing a personal attack from withint (i.e. hostile behavior by one user in the conversation directed towards another) or remaining civil throughout. The Reddit Change My View dataset is labelled with whether or not a coversation eventually had a comment removed by a moderator for violation of Rule 2: \"Don't be rude or hostile to others users.\""], "all_classes": null, "length": 4779}
{"pred": " The article does not mention any datasets used in the experiment.", "answers": ["build a new one, collect INLINEFORM0 cases from China Judgments Online"], "all_classes": null, "length": 4109}
{"pred": " The article discusses the use of a single multilingual multi-domain NMT model for grammatical error correction, style transfer, and monolingual transfer. The model is trained on parallel corpora of erroneous and corrected sentences for each language and domain, and is evaluated on the same data. The model is also evaluated on GEC and style transfer tasks, and is shown to be effective in correcting grammatical errors and adapting the output style to desired styles. The article concludes by noting that the model is a useful tool for monolingual transfer and can be extended to other languages and domains.", "answers": ["Unanswerable"], "all_classes": null, "length": 4572}
{"pred": " The method is better than the state-of-the-art.", "answers": ["absolute improvement of 18.2% over the Pointer-Gen baseline"], "all_classes": null, "length": 4091}
{"pred": " The human judgements were assembled by manually checking the translations and comparing them to the original English sentences.", "answers": ["50 human annotators ranked a random sample of 100 translations by Adequacy, Fluency and overall ranking on a 5-point scale.", "adequacy, precision and ranking values"], "all_classes": null, "length": 5344}
{"pred": " The model used is a joint model that combines textual and visual representations of documents to predict the quality of a document.", "answers": ["visual model is based on fine-tuning an Inception V3 model BIBREF1 over visual renderings of documents, while our textual model is based on a hierarchical biLSTM. We further combine the two into a joint model. , neural network models", "Inception V3, biLSTM"], "all_classes": null, "length": 4217}
{"pred": " The baseline was a strong model trained on the concatenation of the original parallel and monolingual data.", "answers": ["pivot-based translation relying on a helping language BIBREF10, nduction of phrase tables from monolingual data BIBREF14 , attentional RNN-based model (RNMT) BIBREF2, Transformer model BIBREF18, bi-directional model BIBREF11, multi-to-multi (M2M) model BIBREF8, back-translation BIBREF17", "M2M Transformer"], "all_classes": null, "length": 4542}
{"pred": " The global network features which quantify different aspects of the sharing process are:\n\n1. Size of the largest cascade in the layer (LWCC)\n2. Number of strong/weak connected components (SCC)\n3. Depth of the largest cascade in the layer (DWCC)\n4. Breadth of the largest cascade in the layer (BCC)\n5. Mainstreamness of the layer (M)\n6. Disinformationness of the layer (D)\n7. Structural virality of the layer (SV)\n8. Structural virality of the layer (SV)\n9. Structural virality", "answers": ["Number of Strongly Connected Components (SCC), Size of the Largest Strongly Connected Component (LSCC), Number of Weakly Connected Components (WCC), Size of the Largest Weakly Connected Component (LWCC), Diameter of the Largest Weakly Connected Component (DWCC), Average Clustering Coefficient (CC), Main K-core Number (KC), Density (d)"], "all_classes": null, "length": 4906}
{"pred": " The baseline is not mentioned in the article.", "answers": ["QA PGNet, Multi-decoder QA PGNet with lookup table embedding", "QA PGNet and Multi-decoder QA PGNet"], "all_classes": null, "length": 4600}
{"pred": " unanswerable", "answers": ["answer questions by obtaining information from KB tuples ", "hierarchical matching between questions and relations with residual learning"], "all_classes": null, "length": 4527}
{"pred": " The off-the-shelf reward learning algorithm from RL is adapted to the context of data manipulation and model training.", "answers": ["BIBREF7", " reward learning algorithm BIBREF7"], "all_classes": null, "length": 4841}
{"pred": " The article does not mention what dataset was used.", "answers": ["BioASQ  dataset", "A dataset provided by BioASQ consisting of questions, gold standard documents, snippets, concepts  and ideal and ideal answers."], "all_classes": null, "length": 6810}
{"pred": " The manual Pyramid scores used are not specified in the article.", "answers": [" higher tiers of the pyramid", "following the pyramid framework, we design an annotation scheme"], "all_classes": null, "length": 4771}
{"pred": " The models use gradient-based methods to estimate word importance, which is more accurate than black-box methods and better correlates with human judgments. The gradient-based method is language-independent and can be used to identify under-translated words. The word importance is language-dependent, with content words being more important on Chinese$\\Rightarrow $English and French$\\Rightarrow $English translation, while the word frequency is language-independent. The word importance is also language-dependent, with one-to-many fertility being more important on Japanese$\\Rightarrow $English translation.", "answers": ["Given the contribution matrix, we can obtain the word importance of each input word to the entire output sentence. ", "They compute the gradient of the output at each time step with respect to the input words to decide the importance."], "all_classes": null, "length": 4253}
{"pred": " The state of the art models are not mentioned in the article.", "answers": ["BIBREF9 , BIBREF8 ", "BIBREF9 , BIBREF8"], "all_classes": null, "length": 4855}
{"pred": " The article discusses a new method for learning data manipulation schemes in supervised learning, which can be instantiated for different types of manipulations such as data augmentation and weighting. The method is based on a single algorithm that can be instantiated for different manipulations, and is shown to outperform strong baselines and previous methods in experiments. The article also discusses the connection between supervised learning and reinforcement learning, and how the proposed method can be extrapolated to other contexts.", "answers": ["Low data: SST-5, TREC, IMDB around 1-2 accuracy points better than baseline\nImbalanced labels: the improvement over the base model increases as the data gets more imbalanced, ranging from around 6 accuracy points on 100:1000 to over 20 accuracy points on 20:1000"], "all_classes": null, "length": 4880}
{"pred": " The article discusses the construction of challenging datasets for QA models, focusing on the use of expert knowledge sources and the ability of transformer-based models to learn from such data. The article also explores the ability of these models to learn from synthetic datasets and the potential for using such datasets to improve QA models. The article concludes that QA models have a remarkable ability to master new tasks with minimal performance loss, but that there is still room for improvement in terms of model robustness and consistency.", "answers": ["MULTIPLE CHOICE QUESTION ANSWERING", "multiple-choice"], "all_classes": null, "length": 6396}
{"pred": " The article does not mention any publicly available datasets.", "answers": ["Waseem-dataset, Davidson-dataset,", "Waseem and Hovey BIBREF5, Davidson et al. BIBREF9"], "all_classes": null, "length": 4090}
{"pred": " The article tests their word importance approach on several model architectures, including Transformer, LSTM, and RNN.", "answers": [" Transformer BIBREF1 model and the conventional RNN-Search model BIBREF0", "Transformer, RNN-Search model"], "all_classes": null, "length": 4240}
{"pred": " The keyphrase diversity is measured by the number of unique phrases produced by the model.", "answers": ["average unique predictions, illustrate the difference of predictions between our proposed models, we show an example chosen from the KP20k validation set"], "all_classes": null, "length": 4576}
{"pred": " The question is unanswerable as it is not clear what type of evaluation is proposed for this task.", "answers": ["Answer with content missing: (Evaluation Metrics section) Precision, Recall, F1-scores, Strict match, METEOR, ROUGE-2"], "all_classes": null, "length": 4263}
{"pred": " The article does not mention any specific models that were compared with.", "answers": ["Unidirectional LSTM networks with 2, 6, 7, 8, and  9 layers."], "all_classes": null, "length": 4286}
{"pred": " The professional translation introduces the artifacts.", "answers": ["Yes"], "all_classes": null, "length": 4073}
{"pred": " KAR is a knowledge-augmented MRC model.", "answers": ["Lexicon Embedding Layer, Context Embedding Layer, Coarse Memory Layer, Refined Memory Layer, Answer Span Prediction Layer"], "all_classes": null, "length": 4133}
{"pred": " What is future work planned?\n\nunanswerable", "answers": ["ethical questions about generating sensational headlines, which can be further explored,  improving the sensationalism scorer, investigating the applications of dynamic balancing methods between RL and MLE"], "all_classes": null, "length": 4104}
{"pred": " The article does not provide information on how the dataset models character's profiles.", "answers": ["attributes are determined by human viewers and their impressions of the characters, and are correlated with human-like characteristics"], "all_classes": null, "length": 5136}
{"pred": " The article does not mention which dataset has been used in this work.", "answers": ["Reuters-8 dataset without stop words", "The Reuters-8 dataset (with stop words removed)"], "all_classes": null, "length": 5147}
{"pred": " The approach is demonstrated to improve model performance by an average of 24.3% AUC on Cyber Attack and 18.38% AUC on PoliticianDeath over baseline models.", "answers": ["significant improvements clearly demonstrate that our approach is effective at improving model performance", "By evaluating the performance of the approach using accuracy and AUC"], "all_classes": null, "length": 4489}
{"pred": " The authors present evidence that the model can capture some biases in data annotation and collection by examining the results and the confusion matrices of the fine-tuning strategies. They also mention that the model can differentiate hate and offensive content in most cases, but it misclassifies hate content as offensive or neither due to the context-dependent nature of hate speech.", "answers": ["The authors showed few tweets where neither and implicit hatred content exist but the model was able to discriminate"], "all_classes": null, "length": 4119}
{"pred": " The article does not provide information on which benchmarks the authors achieve the state of the art on.", "answers": ["SimpleQuestions, WebQSP", "WebQSP, SimpleQuestions"], "all_classes": null, "length": 4524}
{"pred": " The article discusses a method for performing monolingual transfer, where a single model is trained to perform both grammatical error correction and style transfer. The model is trained on parallel corpora of erroneous and corrected sentences for the same language, and is able to correct grammatical errors and change the style of the output. The model is evaluated on a test set of 1000 sentence pairs, and is shown to be reliable for grammatical error correction and style transfer. The article also presents results for style transfer in Estonian, Latvian, and English, and shows that the model is able to change the style of the output while", "answers": ["grammatical, spelling and word order errors", "spelling, word order and grammatical errors"], "all_classes": null, "length": 4579}
{"pred": " The authors found ironic data on twitter by scraping tweets containing the word \"irony\" and filtering out tweets that were not in English. They then manually labeled the tweets as either ironic or non-ironic.", "answers": ["They developed a classifier to find ironic sentences in twitter data", "by crawling"], "all_classes": null, "length": 4599}
{"pred": " The article discusses a neural extractive summarization model that takes into account the local context of each sentence within a document, as well as the global context of the entire document. The model is evaluated on two large-scale datasets of scientific papers, and compared to previous models. The results show that the model outperforms previous models on both datasets, and that the benefits of the local context become stronger as the length of the document increases. The article also presents an ablation study to assess the relative contributions of the global and local models, and concludes that the benefits of the local context become stronger as the length of the document increases.", "answers": ["global (the whole document), local context (e.g., the section/topic)", "global (the whole document) and the local context (e.g., the section/topic) "], "all_classes": null, "length": 4287}
{"pred": " What does KBQA abbreviate for?\n\nunanswerable", "answers": ["Knowledge Base Question Answering", "Knowledge Base Question Answering "], "all_classes": null, "length": 4521}
{"pred": " The article discusses how LDA and Gibbs sampling are utilized to evaluate ISWC and WWW publications. The authors use Gibbs sampling to estimate the parameters of the LDA model and then apply it to the ISWC and WWW publications to discover topics and generate tags. They also discuss the sparsity and cold-start problems in recommendation systems based on LDA and provide solutions to these issues.", "answers": ["the LDA approaches to recommendation systems and given the importance of research, we have studied recent impressive articles on this subject and presented a taxonomy of recommendation systems based on LDA of the recent research, we evaluated ISWC and WWW conferences articles from DBLP website and used the Gibbs sampling algorithm as an evaluation parameter", "discover the trends of the topics and find relationship between LDA topics and paper features and generate trust tags,  learn a LDA model with 100 topics; $\\alpha =0.01$, $\\beta = 0.01$ and using Gibbs sampling as a parameter estimation"], "all_classes": null, "length": 4322}
{"pred": " Yes, the authors hypothesize that humans' robustness to noise is due to their general knowledge.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4127}
{"pred": " The question is about the gender representation in the analyzed corpora and the impact of this representation on the performance of an ASR system. The article discusses the gender representation in the analyzed corpora and the impact of this representation on the performance of an ASR system. The article concludes that the gender representation in the analyzed corpora is unbalanced and that this representation has a significant impact on the performance of an ASR system. The article also discusses the role of gender in the performance of an ASR system and the potential impact of the gender representation in the analyzed corpora on the performance of an ASR system. The article concludes that", "answers": ["Women represent 33.16% of the speakers"], "all_classes": null, "length": 4055}
{"pred": " The baseline model is not mentioned in the article.", "answers": ["by answering always YES (in batch 2 and 3) "], "all_classes": null, "length": 6817}
{"pred": " The highest recall score is 0.2862.", "answers": ["0.7033", "0.7033"], "all_classes": null, "length": 6810}
{"pred": " The evaluation criteria and metrics used to evaluate the generated text are:\n\n1. Event-level evaluation: The model is evaluated based on the number of events it can correctly generate, the accuracy of the generated text, and the fluency of the text.\n2. News-level evaluation: The model is evaluated based on the overall quality of the generated text, including factual correctness, fluency, and readability.\n3. Human evaluation: The model is evaluated based on the quality of the generated text as perceived by human journalists.", "answers": ["BLEU , NIST , METEOR , ROUGE-L, CIDEr , evaluation script, automatic evaluation, human evaluation, minimum edit evaluation, word error rate (WER), factual errors and their types, fluency issues, acceptability of the output for production use in a news agency", "BLEU, NIST, METEOR, ROUGE-L, CIDEr"], "all_classes": null, "length": 4738}
{"pred": " The article does not mention what model the researchers used for their system.", "answers": ["AllWords model by counting the frequencies of all the remaining words and training a multinomial Naive Bayes classifier"], "all_classes": null, "length": 4177}
{"pred": " The article does not provide information on which real-world datasets are used.", "answers": ["Tweets related to CyberAttack and tweets related to PoliticianDeath", "cyber security (CyberAttack), death of politicians (PoliticianDeath)"], "all_classes": null, "length": 4481}
{"pred": " The article discusses the use of machine learning and deep learning methods for Recognizing Question Entailment (RQE) in the medical domain. The authors present a hybrid IR+RQE QA system that outperforms the best results in the medical QA challenge at TREC 2017 LiveQA. The system uses an IR-based QA system with a RQE module to retrieve answers to a given question. The authors also present a medical question-answering dataset and evaluate the performance of the QA system on the TREC-2017 LiveQA medical test questions. The results show that the hybrid IR+RQE QA system outperforms", "answers": ["Logistic Regression, neural networks"], "all_classes": null, "length": 7257}
{"pred": " The strong baseline is the baseline model.", "answers": ["Conditional Copy (CC) model ", "delayed copy model (DEL),  template system (TEM), conditional copy (CC), NCP+CC (NCP)"], "all_classes": null, "length": 4746}
{"pred": " The invertibility condition is a constraint that ensures that the projection function is invertible, which is important for the derivation of exact inference and marginal likelihood computation.", "answers": ["The neural projector must be invertible.", "we constrain our neural projector with two requirements: (1) INLINEFORM0 and (2) INLINEFORM1 exists"], "all_classes": null, "length": 4323}
{"pred": " The article does not provide information on the type of classifiers used.", "answers": ["probabilistic model", "Logistic Regression, Multilayer Perceptron"], "all_classes": null, "length": 4475}
{"pred": " The size of the real-world civil case dataset is not mentioned in the article.", "answers": ["100 000 documents", " INLINEFORM1 cases"], "all_classes": null, "length": 4104}
{"pred": " The data was collected from MTurk workers.", "answers": ["The data was collected using 3 components: describe a series of pilot studies that were conducted to collect commonsense inference questions, then discuss the resulting data collection of questions, texts and answers via crowdsourcing on Amazon Mechanical Turk and gives information about some necessary postprocessing steps and the dataset validation."], "all_classes": null, "length": 4536}
{"pred": " The article does not mention any methods used to reduce data sparsity effects.", "answers": ["Back Translation, Mix-Source Approach", "data augmentation"], "all_classes": null, "length": 4123}
{"pred": " The difference in performance between proposed model and baselines is not mentioned in the article.", "answers": ["Metric difference between Aloha and best baseline score:\nHits@1/20: +0.061 (0.3642 vs 0.3032)\nMRR: +0.0572(0.5114 vs 0.4542)\nF1: -0.0484 (0.3901 vs 0.4385)\nBLEU: +0.0474 (0.2867 vs 0.2393)"], "all_classes": null, "length": 5151}
{"pred": " The article discusses the use of offensive language in Arabic social media, including the use of vulgar and hate speech. The authors present a methodology for building a large dataset of Arabic offensive language tweets, which they use to analyze the characteristics of offensive language in Arabic. They find that vulgar and hate speech are the most common types of offensive language, and that the use of dialectal and contextualized embeddings can improve classification performance. The authors also present a detailed analysis of the most common types of offensive language, as well as the most common errors in the classification of offensive language tweets.", "answers": ["Frequent use of direct animal name calling, using simile and metaphors, through indirect speech like sarcasm, wishing evil to others, name alteration, societal stratification, immoral behavior and sexually related uses.", "Direct name calling, Simile and metaphor, Indirect speech, Wishing Evil, Name alteration, Societal stratification, Immoral behavior, Sexually related"], "all_classes": null, "length": 4566}
{"pred": " The authors show that their learned policy generalizes better than existing solutions to unseen games by evaluating their method on unseen games in the CoinCollector and CookingWorld settings. They achieve a score of 0.5 in CoinCollector and a score of 0.4 in CookingWorld, which is higher than the score achieved by existing solutions.", "answers": ["promising results by solving almost half of the unseen games, most of the lost games are in the hardest set, where a very long sequence of actions is required for winning the game"], "all_classes": null, "length": 4964}
{"pred": " The goal is to investigate the gender bias in NLP performance in the news broadcast domain and Anchor role, and to understand how it is related to the gender representation in the data.", "answers": ["create fair systems", " broadcast recordings are also a valuable source of data for the speech processing community, recent works uncovering gender bias in several natural language processing (NLP) tools"], "all_classes": null, "length": 4063}
{"pred": " The article discusses the construction of a computational model to identify dogmatism in text, using a corpus of social media posts annotated with dogmatism scores. The model is trained on a large corpus of Reddit posts annotated with dogmatism scores, and features are extracted from the posts to train the model. The model is then used to predict the dogmatism level of new posts, and the results are analyzed to identify linguistic features of dogmatism. The article also discusses the relationship between dogmatism and other psychological phenomena, and the impact of dogmatism on conversations on social media. The article concludes by discussing the potential for future", "answers": ["logistic regression models", "logistic regression models based on unigram bag-of-words features (BOW), sentiment signals (SENT), the linguistic features from our earlier analyses (LING), and combinations of these features."], "all_classes": null, "length": 4208}
{"pred": " Yes, they released their data set of academic papers.", "answers": ["No", "Unanswerable"], "all_classes": null, "length": 4181}
{"pred": " The state-of-the-art system is the Message Passing Attention network for Document understanding (MPAD).", "answers": ["doc2vec , CNN, DAN, Tree-LSTM, DRNN, LSTMN, C-LSTM, SPGK, WMD, S-WMD, Semantic-CNN, LSTM-GRNN, HN-ATT"], "all_classes": null, "length": 4169}
{"pred": " The article discusses the attribution-based approach for estimating word importance in neural machine translation (NMT) models. The approach uses the integrated gradients method to attribute the output to the input words with the integration of first-order derivatives. The article also explores the word importance in NMT models and analyzes the linguistic properties of important words. The article concludes that the word importance method consistently outperforms black-box methods in estimating word importance and can identify under-translated words. The article also discusses the potential usage of word importance to improve NMT models, such as better word importance for better decoding and better input embedding for better translation.", "answers": ["They measured the under-translated words with low word importance score as calculated by Attribution.\nmethod", "we ask ten human annotators to manually label the under-translated input words, and at least two annotators label each input-hypothesis pair"], "all_classes": null, "length": 4246}
{"pred": " The model is applied to two datasets: Conversations Gone Awry and CMV.", "answers": [" `Conversations Gone Awry' dataset, subreddit ChangeMyView", "An expanded version of the existing 'Conversations Gone Awry' dataset and the ChangeMyView dataset, a subreddit whose only annotation is whether the conversation required action by the Reddit moderators. "], "all_classes": null, "length": 4718}
{"pred": " No, they did not collect their own data.", "answers": ["No"], "all_classes": null, "length": 4117}
{"pred": " The article does not mention the dataset used.", "answers": ["Europarl corpus , WMT newstest 2014, News-Commentary-11, Wikipedia from WMT 2014, Multi-UN, EU-Bookshop, Rapid, Common-Crawl (WMT 2017)", "Europarl tests from 2006, 2007, 2008; WMT newstest 2014."], "all_classes": null, "length": 4184}
{"pred": " Yes, the two datasets were collected.", "answers": ["No", "No"], "all_classes": null, "length": 4484}
{"pred": " A second order co-occurrence matrix is a matrix that represents the co-occurrence of two words in a text corpus. It is a matrix where each cell represents the number of times two words appear together in the corpus. The matrix is used to measure the similarity between two words by counting the number of times they co-occur in the corpus. The matrix is used to measure the similarity between two words by counting the number of times they co-occur in the corpus.", "answers": ["frequencies of the other words which occur with both of them (i.e., second order co–occurrences)", "The matrix containing co-occurrences of the words which occur with the both words of every given pair of words."], "all_classes": null, "length": 4271}
{"pred": " The article does not report any evaluation metrics.", "answers": ["precision, recall, F1 and accuracy", "precision, recall, F1 , accuracy "], "all_classes": null, "length": 4101}
{"pred": " Yes, the authors report results only on English data.", "answers": ["Yes", "Unanswerable"], "all_classes": null, "length": 4770}
{"pred": " The article does not provide information on how annotators are matched to instances.", "answers": ["Annotations from experts are used if they have already been collected."], "all_classes": null, "length": 4377}
{"pred": " The size of the dataset is not mentioned in the article.", "answers": ["13,939"], "all_classes": null, "length": 4489}
{"pred": " No, the data is not de-identified.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4592}
{"pred": " The article does not mention whether the models use pretrained embeddings.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 4457}
{"pred": " The article discusses the use of AMR for text summarization and proposes a new method for extracting summary graphs. The article also evaluates the effectiveness of the pipeline using ROGUE and discusses the limitations of the ROGUE metric for evaluating abstractive summaries. The article concludes by proposing future directions for the pipeline.", "answers": ["Quantitative evaluation methods using ROUGE, Recall, Precision and F1.", "standard ROGUE metric, Recall, Precision and INLINEFORM0 scores for ROGUE-1,  INLINEFORM2 scores for ROGUE-2 and ROGUE-L"], "all_classes": null, "length": 4395}
{"pred": " The baseline methods are NaiveNN, FANN, and DAS.", "answers": ["(1) Naive, (2) mSDA BIBREF7, (3) NaiveNN, (4) AuxNN BIBREF4, (5) ADAN BIBREF16, (6) MMD", "non-domain-adaptive baseline with bag-of-words representations and SVM classifier, mSDA, non-domain-adaptive CNN trained on source domain, neural model that exploits auxiliary tasks, adversarial training to reduce representation difference between domains, variants of deep CNNs are used for encoding images and the MMDs of multiple layers are jointly minimized"], "all_classes": null, "length": 5063}
{"pred": " The article does not provide information on the absolute accuracy of the system.", "answers": ["59.4% on wikipedia dataset, 93.4% on peer-reviewed archive AI papers, 77.1%  on peer-reviewed archive Computation and Language papers, and 79.9% on peer-reviewed archive Machine Learning papers"], "all_classes": null, "length": 4203}
{"pred": " The paper explores various embedding techniques, including word2vec, GloVe, and fastText.", "answers": ["Skip–gram, CBOW", "integrated vector-res, vector-faith, Skip–gram, CBOW"], "all_classes": null, "length": 4259}
{"pred": " The two large-scale datasets used are the US dataset and the Italian dataset.", "answers": ["US dataset, Italian dataset", "US dataset, Italian dataset"], "all_classes": null, "length": 4857}
{"pred": " The article discusses how profile changes vary for influential leaders and their followers over the #LokSabhaElections2019 social movement. The article analyzes the profile changes of 1,293 political handles and 55 million followers of these handles. The article also discusses the political inclination of users on Twitter through profile attributes and how the behavior contagion effect is similar to the behavior of opinion leaders. The article concludes that the behavior of users on Twitter can be categorized into organic and inorganic behavior. The article also discusses how profile changes vary for influential leaders and their followers over the #LokSabhaElections2019 social movement.", "answers": ["Influential leaders are more likely to change their profile attributes than their followers; the leaders do not change their usernames, while their followers change their usernames a lot; the leaders  tend to make new changes related to previous attribute values, while the followers make comparatively less related changes to previous attribute values."], "all_classes": null, "length": 5092}
{"pred": " Yes, there is space for further improvement.", "answers": [" by testing humans on a random subset of 50 named entity and 50 common noun validation questions that the psr ensemble could not answer correctly", "majority of questions that our system could not answer so far are in fact answerable"], "all_classes": null, "length": 4232}
{"pred": " The article discusses the use of cost-sensitive classification in BERT for the Shared Task on Fine-Grained Propaganda Detection. The authors use cost-sensitive learning to incorporate cost-sensitivity into BERT to make the model more suitable for dissimilar datasets. They also explore the use of cost-sensitive learning to improve the model's ability to generalize on dissimilar data. The article also discusses the use of cost-sensitive learning to improve the model's ability to generalize on dissimilar data. The article concludes that the use of cost-sensitive learning improves the model's ability to generalize on dissimilar data.", "answers": ["precision, recall , F1 score"], "all_classes": null, "length": 4515}
{"pred": " The article does not mention if the TREC 2017 LiveQA-Med participants' results are reported only on English data.", "answers": ["Unanswerable", "Yes"], "all_classes": null, "length": 7251}
{"pred": " The article does not provide information on the size of the data set used for the experiments.", "answers": ["a sample of  29,794 wikipedia articles and 2,794 arXiv papers "], "all_classes": null, "length": 4187}
{"pred": " Yes, they recommend translating the premise and hypothesis together.", "answers": ["No", "No"], "all_classes": null, "length": 4071}
{"pred": " The metrics used to establish that this makes chatbots more knowledgeable and better at learning and conversation are not explicitly stated in the article.", "answers": ["Coverage, Avg. MCC and avg. +ve F1 score", "strategy formulation ability, we introduce a measure called Coverage( INLINEFORM0 ), To evaluate the predictive performance, we use Avg. MCC and avg. +ve F1 score"], "all_classes": null, "length": 5869}
{"pred": " The article discusses the process of conducting text analysis using computational methods, including the identification of research questions, data selection, concept measurement, and analysis. The article emphasizes the importance of interdisciplinary collaboration and iterative processes to ensure that the analysis is grounded in theory and aligned with the research questions. The article also highlights the challenges of operationalizing and analyzing concepts, and the need for close reading and validation. The article concludes by emphasizing the value of computational text analysis for exploring and answering research questions.", "answers": ["Domain experts and fellow researchers can provide feedback on questions and help with dynamically revising them., connect to multiple disciplines, dual use", "Modeling considerations:  the variables (both predictors and outcomes)  are rarely simply binary or categorical;  using a particular classification scheme means deciding which variations are visible,; Supervised and unsupervised learning are the most common approaches to learning from data;  the unit of text that we are labeling (or annotating, or coding), either automatic or manual, can sometimes be different than one's final unit of analysis."], "all_classes": null, "length": 8530}
{"pred": " The article does not mention the dataset used for analysis.", "answers": ["Unanswerable"], "all_classes": null, "length": 8508}
{"pred": " unanswerable", "answers": ["Energy with accuracy of 0.538", "Energy"], "all_classes": null, "length": 10349}
{"pred": " The article does not provide information on the background of the authors.", "answers": ["Unanswerable"], "all_classes": null, "length": 8506}
{"pred": " The article discusses the use of argumentation theory and machine learning methods for analyzing argumentation in user-generated content on the Web. The article presents a novel argumentation mining framework that uses argumentation theory to model and analyze micro-level argumentation in user-generated content. The framework is applied to a corpus of user-generated content from four different domains and annotated by four annotators. The results show that the framework can be used to identify argument components in user-generated content and that the use of argumentation theory can help to overcome the limitations of existing argumentation theories. The article also presents a novel argumentation mining task and a", "answers": ["Structural Support Vector Machine", "SVMhmm "], "all_classes": null, "length": 14468}
{"pred": " Yes, they model semantics.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 12950}
{"pred": " The article describes a framework for designing and developing conversational systems that can interact with multiple users and chatbots in a multi-party chat. The framework includes norms for conversational systems, dialogues, and conversational systems that can be used in a multi-party chat. The framework also includes a multi-party governance service that uses the conversational systems to enforce exchange of compliant utterances. The framework is implemented as a hybrid conceptual architecture and a micro-service implementation of SABIA. The article also presents the results of a test that simulates users interacting with the system and the results of a test that uses eight concurrent simulated", "answers": ["ELIZA,  PARRY, A.L.I.C.E., Cleverbot"], "all_classes": null, "length": 13395}
{"pred": " The article does not mention the dataset used.", "answers": ["corpus of state speeches delivered during the annual UN General Debate", "corpus of state speeches delivered during the annual UN General Debate"], "all_classes": null, "length": 8647}
{"pred": " The text embedding methodologies used are Paragraph Vectors (PV), Latent Dirichlet Allocation (LDA), and Markov Stability (MS).", "answers": ["Document to Vector (Doc2Vec)", "Doc2Vec, PV-DBOW model"], "all_classes": null, "length": 8196}
{"pred": " The article discusses the identification of argument components in user-generated content on the Web, using argumentation theory and machine learning methods. The article proposes a modified Toulmin's model for argumentation and an annotation scheme based on the Toulmin's model for short documents. The article also discusses the identification of argument components using various machine learning methods and proposes a computational model for identifying argument components in user-generated content on the Web.", "answers": ["claim, premise, backing, rebuttal, and refutation", "claim, premise, backing, rebuttal, refutation"], "all_classes": null, "length": 14472}
{"pred": " The article does not report results only on English data.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 14465}
{"pred": " The article does not mention any datasets used.", "answers": ["Custom dataset with user questions; set of documents, twitter posts and news articles, all related to finance.", "a self-collected financial intents dataset in Portuguese"], "all_classes": null, "length": 13401}
{"pred": " Yes, they analyze specific derogatory words.", "answers": ["Yes", "Yes"], "all_classes": null, "length": 12952}
{"pred": " A node in the network approach represents a state in the network.", "answers": ["Unanswerable", "Unanswerable"], "all_classes": null, "length": 8641}
{"pred": " The data in the new corpus is sourced from user-generated content on the Web.", "answers": ["user comments to newswire articles or to blog posts, forum posts, blog posts, newswire articles", "refer to each article, blog post, comment, or forum posts as a document"], "all_classes": null, "length": 14481}
{"pred": " The article does not provide a clear answer to this question.", "answers": ["act paragraphs containing any word from a predetermined list of LGTBQ terms "], "all_classes": null, "length": 12970}
{"pred": " Yes, they demonstrate why interdisciplinary insights are important.", "answers": ["No", "No"], "all_classes": null, "length": 8509}
{"pred": " What kind of issues (that are not on the forefront of computational text analysis) do they tackle?\n\nunanswerable", "answers": ["identifying the questions we wish to explore, Can text analysis provide a new perspective on a “big question” that has been attracting interest for years?, How can we explain what we observe?, hope to connect to multiple disciplines"], "all_classes": null, "length": 8555}
{"pred": " The article discusses the challenges of engineering a multi-party chatbot system, such as coordinating the exchange of compliant utterances and responding to multiple users simultaneously. The authors present a hybrid conceptual architecture and its implementation with a finance advisory system, and evaluate the system with a multi-party governance service that uses that specification to enforce exchange of compliant utterances. The article also discusses the evaluation metrics used to measure the system's performance.", "answers": ["precision, recall, F1 and accuracy", "Response time, resource consumption (memory, CPU, network bandwidth), precision, recall, F1, accuracy."], "all_classes": null, "length": 13391}
{"pred": " No, they do not use number of votes as an indicator of preference.", "answers": ["No", "Yes"], "all_classes": null, "length": 8643}
{"pred": " The article discusses the challenges of argumentation mining in different registers and domains. The article proposes a computational model for identifying argument components in user-generated Web content, which is based on machine learning. The article also proposes a modification of Toulmin's model for short documents. The article discusses the challenges of argumentation mining in different registers and domains, such as the lack of annotated data, the difficulty of distinguishing between backing and premises, and the need for a computational model that can capture argumentation on the Web. The article also proposes a computational model for identifying argument components in user-generated Web content.", "answers": ["linguistic variability"], "all_classes": null, "length": 14469}
{"pred": " The datasets were created using a consistent annotation protocol and guidelines, and the annotation process was carried out by a team of annotators who were fluent in the languages being annotated. The annotation process involved translating and adapting the annotation guidelines developed for the English SimLex-999 dataset, and the resulting datasets were manually and consistently annotated by the annotators. The annotation process was carried out by a team of annotators who were fluent in the languages being annotated.", "answers": ["1. Each annotator must assign an integer score between 0 and 6 (inclusive) indicating how semantically similar the two words in a given pair are. A score of 6 indicates very high similarity (i.e., perfect synonymy), while zero indicates no similarity., 2. Each annotator must score the entire set of 1,888 pairs in the dataset.,  able to use external sources (e.g. dictionaries, thesauri, WordNet) if required, not able to communicate with each other during the annotation process"], "all_classes": null, "length": 14722}
{"pred": " The article discusses the challenges and issues in argumentation mining, including the lack of annotated data, the selection of an appropriate argumentation theory, and the identification of argument components. The article proposes a computational model for identifying argument components in user-generated Web content, which includes a modified Toulmin's model and a scheme for argumentation mining. The article also presents a novel argumentation mining corpus and a software package for analyzing argumentation in user-generated Web content.", "answers": ["Unanswerable"], "all_classes": null, "length": 14471}
{"pred": " The 12 languages covered in the article are: English, French, German, Italian, Russian, Spanish, Chinese, Japanese, Korean, Welsh, Yue Chinese, and Kiswahili.", "answers": ["Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese", "Chinese Mandarin, Welsh, English, Estonian, Finnish, French, Hebrew, Polish, Russian, Spanish, Kiswahili, Yue Chinese"], "all_classes": null, "length": 14660}
